---
- include: do_we_have_a_dump.yml

# It's important that we send the file to the server without `become`. Otherwise, our tarfile stays
# in ansible's cache without being properly cleaned up (at least at the time of this writing).
# This results in running out of disk space on our vagrant box in situations where the tarfile is
# large. When we run as root, ansible's cache is properly cleaned up right after the `copy` action.
- block:
  - name: Copy over initial dump
    copy:
      src: "{{ zbackup_initial_dump_file }}"
      dest: /tmp/to_dump.tar.gz
  - name: Get our file type
    command: "/usr/bin/file /tmp/to_dump.tar.gz"
    register: initial_dump_filetype
  - name: Send the archive ungzipped
    shell: "gzip -dc /tmp/to_dump.tar.gz | {{ zbackup_storage_path }}/dump"
    when: "\"gzip\" in initial_dump_filetype.stdout"
    become: yes
    become_user: "{{ zbackup_owner }}"
  - name: Send the uncompressed file into the backup
    shell: "{{ zbackup_storage_path }}/dump < /tmp/to_dump.tar.gz" 
    when: "\"gzip\" not in initial_dump_filetype.stdout"
    become: yes
    become_user: "{{ zbackup_owner }}"
  - name: Clean up after ourselves
    file:
      path: "/tmp/to_dump.tar.gz"
      state: absent
  - include: do_we_have_a_dump.yml
  when: not latest_timestamp.stat.exists and zbackup_initial_dump_file != ''

- block:
  - name: Run initial dump fetch command
    shell: "{{ zbackup_initial_dump_fetch_command }} | {{ zbackup_storage_path }}/dump"
  - include: do_we_have_a_dump.yml
  become: yes
  become_user: "{{ zbackup_owner }}"
  when: not latest_timestamp.stat.exists and zbackup_initial_dump_fetch_command != ''

- fail:
    msg: We couldn't manage to import an initial dump!
  when: not latest_timestamp.stat.exists
